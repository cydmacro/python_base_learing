#!/usr/bin/env python3
"""
å•†ä¸šåœºæ™¯æŒ‘æˆ˜æ¼”ç¤º

æœ¬æ–‡ä»¶å±•ç¤ºäº†å¤§æ¨¡å‹åœ¨å®é™…å•†ä¸šåœºæ™¯ä¸­çš„åº”ç”¨æŒ‘æˆ˜å’Œè§£å†³æ–¹æ¡ˆï¼Œ
åŒ…æ‹¬ï¼šå®¢æˆ·æœåŠ¡ã€å†…å®¹ç”Ÿæˆã€æ•°æ®åˆ†æã€å†³ç­–æ”¯æŒç­‰ä¸šåŠ¡åœºæ™¯ã€‚

æŠ€æœ¯è¦ç‚¹ï¼š
- çœŸå®å•†ä¸šåœºæ™¯çš„é—®é¢˜å»ºæ¨¡
- å¤šè½®å¯¹è¯ä¸ä¸Šä¸‹æ–‡ç®¡ç†
- ä¸“ä¸šé¢†åŸŸçŸ¥è¯†çš„åº”ç”¨
- å•†ä¸šè§„åˆ™ä¸çº¦æŸçš„å¤„ç†
"""

from typing import List, Dict, Any, Optional
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain.schema import HumanMessage, AIMessage
from pydantic import BaseModel, Field
from datetime import datetime, timedelta
import json
import random


class CustomerProfile(BaseModel):
    """å®¢æˆ·æ¡£æ¡ˆæ¨¡å‹"""
    customer_id: str = Field(description="å®¢æˆ·ID")
    name: str = Field(description="å®¢æˆ·å§“å")
    tier: str = Field(description="å®¢æˆ·ç­‰çº§", default="regular")
    purchase_history: List[Dict] = Field(description="è´­ä¹°å†å²", default_factory=list)
    preferences: List[str] = Field(description="åå¥½æ ‡ç­¾", default_factory=list)
    contact_history: List[Dict] = Field(description="è”ç³»å†å²", default_factory=list)


class BusinessInsight(BaseModel):
    """å•†ä¸šæ´å¯Ÿæ¨¡å‹"""
    insight_type: str = Field(description="æ´å¯Ÿç±»å‹")
    title: str = Field(description="æ´å¯Ÿæ ‡é¢˜")
    description: str = Field(description="è¯¦ç»†æè¿°")
    confidence: float = Field(description="ç½®ä¿¡åº¦", ge=0.0, le=1.0)
    recommendations: List[str] = Field(description="å»ºè®®è¡ŒåŠ¨", default_factory=list)
    impact_level: str = Field(description="å½±å“çº§åˆ«", default="medium")


class BusinessChallengesDemo:
    """å•†ä¸šåœºæ™¯æŒ‘æˆ˜æ¼”ç¤ºç±»"""
    
    def __init__(self, model_name: str = "qwen-plus"):
        """åˆå§‹åŒ–å•†ä¸šåœºæ™¯æ¼”ç¤ºå™¨"""
        # self.llm = ChatOpenAI(
        #     model=model_name,
        #     base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
        #     api_key="your_api_key_here",  # è¯·æ›¿æ¢ä¸ºæœ‰æ•ˆçš„APIå¯†é’¥
        #     temperature=0.7
        # )
        self.llm = ChatOpenAI(
            model_name="qwen-plus",
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
            api_key="sk-b860c820ce0249d9ac316d4598e81eb5",
            temperature=0.3
        )
        
        # åˆå§‹åŒ–æ–°çš„æ¶ˆæ¯å†å²ç®¡ç†
        self.message_history = ChatMessageHistory()
        self.max_messages = 10  # ä¿æŒæœ€è¿‘10æ¡æ¶ˆæ¯
    
    def customer_service_bot(self, customer_query: str, customer_profile: CustomerProfile) -> str:
        """æ™ºèƒ½å®¢æœåœºæ™¯æ¼”ç¤º"""
        # æ„å»ºä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„å®¢æœæç¤º
        service_prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å®¢æœä»£è¡¨ã€‚è¯·æ ¹æ®å®¢æˆ·æ¡£æ¡ˆæä¾›ä¸ªæ€§åŒ–çš„æœåŠ¡ã€‚

å®¢æˆ·æ¡£æ¡ˆä¿¡æ¯ï¼š
- å®¢æˆ·å§“åï¼š{customer_name}
- å®¢æˆ·ç­‰çº§ï¼š{customer_tier}
- è´­ä¹°å†å²ï¼š{purchase_history}
- åå¥½æ ‡ç­¾ï¼š{preferences}
- è”ç³»å†å²ï¼š{contact_history}

æœåŠ¡åŸåˆ™ï¼š
1. ç§°å‘¼å®¢æˆ·å§“åï¼Œä½“ç°ä¸ªæ€§åŒ–æœåŠ¡
2. æ ¹æ®å®¢æˆ·ç­‰çº§è°ƒæ•´æœåŠ¡æ€åº¦ï¼ˆVIPå®¢æˆ·æ›´åŠ å…³æ³¨ï¼‰
3. å‚è€ƒè´­ä¹°å†å²æä¾›ç›¸å…³å»ºè®®
4. è€ƒè™‘å®¢æˆ·åå¥½è¿›è¡Œæ¨è
5. ä¿æŒä¸“ä¸šã€å‹å–„ã€è§£å†³é—®é¢˜çš„æ€åº¦

è¯·å›å¤å®¢æˆ·çš„è¯¢é—®ï¼š"""),
            ("human", "{query}")
        ])
        
        chain = service_prompt | self.llm
        response = chain.invoke({
            "customer_name": customer_profile.name,
            "customer_tier": customer_profile.tier,
            "purchase_history": json.dumps(customer_profile.purchase_history, ensure_ascii=False),
            "preferences": ", ".join(customer_profile.preferences),
            "contact_history": json.dumps(customer_profile.contact_history[-3:], ensure_ascii=False),  # æœ€è¿‘3æ¬¡è”ç³»
            "query": customer_query
        })
        
        return response.content
    
    def content_generation_pipeline(self, content_type: str, target_audience: str, 
                                  key_points: List[str], brand_tone: str = "professional") -> Dict[str, Any]:
        """å†…å®¹ç”Ÿæˆæµæ°´çº¿æ¼”ç¤º"""
        
        # 1. å†…å®¹ç­–ç•¥è§„åˆ’
        strategy_prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯å†…å®¹ç­–ç•¥ä¸“å®¶ã€‚è¯·ä¸ºä»¥ä¸‹å†…å®¹ç”Ÿæˆéœ€æ±‚åˆ¶å®šç­–ç•¥ï¼š
- åˆ†æç›®æ ‡å—ä¼—ç‰¹ç‚¹
- ç¡®å®šå†…å®¹ç»“æ„å’Œè¦ç‚¹
- åˆ¶å®šä¼ æ’­ç­–ç•¥"""),
            ("human", """å†…å®¹ç±»å‹ï¼š{content_type}
ç›®æ ‡å—ä¼—ï¼š{target_audience}
å…³é”®è¦ç‚¹ï¼š{key_points}
å“ç‰Œè°ƒæ€§ï¼š{brand_tone}

è¯·åˆ¶å®šå†…å®¹ç­–ç•¥ï¼š""")
        ])
        
        # 2. å†…å®¹åˆ›ä½œ
        creation_prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸“ä¸šçš„å†…å®¹åˆ›ä½œè€…ã€‚æ ¹æ®ç­–ç•¥è¦æ±‚åˆ›ä½œé«˜è´¨é‡å†…å®¹ï¼š
- éµå¾ªå“ç‰Œè°ƒæ€§
- ç¬¦åˆç›®æ ‡å—ä¼—ç‰¹ç‚¹
- åŒ…å«æ‰€æœ‰å…³é”®è¦ç‚¹
- ç¡®ä¿å†…å®¹å¸å¼•åŠ›å’Œå®ç”¨æ€§"""),
            ("human", """åŸºäºä»¥ä¸‹ç­–ç•¥åˆ›ä½œå†…å®¹ï¼š

ç­–ç•¥ï¼š{strategy}

è¯·åˆ›ä½œå†…å®¹ï¼š""")
        ])
        
        # 3. å†…å®¹ä¼˜åŒ–
        optimization_prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯å†…å®¹ä¼˜åŒ–ä¸“å®¶ã€‚è¯·å¯¹å†…å®¹è¿›è¡Œå¤šç»´åº¦ä¼˜åŒ–ï¼š
1. SEOå…³é”®è¯ä¼˜åŒ–
2. å¯è¯»æ€§æå‡
3. äº’åŠ¨æ€§å¢å¼º
4. è½¬åŒ–ç‡ä¼˜åŒ–"""),
            ("human", """åŸå§‹å†…å®¹ï¼š{original_content}

è¯·ä¼˜åŒ–å†…å®¹ï¼š""")
        ])
        
        # æ‰§è¡Œå†…å®¹ç”Ÿæˆæµç¨‹
        try:
            # æ­¥éª¤1ï¼šç­–ç•¥è§„åˆ’
            strategy_chain = strategy_prompt | self.llm
            strategy_result = strategy_chain.invoke({
                "content_type": content_type,
                "target_audience": target_audience,
                "key_points": ", ".join(key_points),
                "brand_tone": brand_tone
            })
            
            # æ­¥éª¤2ï¼šå†…å®¹åˆ›ä½œ
            creation_chain = creation_prompt | self.llm
            content_result = creation_chain.invoke({
                "strategy": strategy_result.content
            })
            
            # æ­¥éª¤3ï¼šå†…å®¹ä¼˜åŒ–
            optimization_chain = optimization_prompt | self.llm
            optimized_result = optimization_chain.invoke({
                "original_content": content_result.content
            })
            
            return {
                "strategy": strategy_result.content,
                "original_content": content_result.content,
                "optimized_content": optimized_result.content,
                "generation_success": True
            }
            
        except Exception as e:
            return {
                "error": str(e),
                "generation_success": False
            }
    
    def business_data_analyst(self, data_description: str, business_questions: List[str]) -> List[BusinessInsight]:
        """å•†ä¸šæ•°æ®åˆ†æå¸ˆæ¼”ç¤º"""
        insights = []
        
        for question in business_questions:
            analysis_prompt = ChatPromptTemplate.from_messages([
                ("system", """ä½ æ˜¯èµ„æ·±çš„å•†ä¸šæ•°æ®åˆ†æå¸ˆã€‚è¯·åŸºäºæ•°æ®æè¿°åˆ†æä¸šåŠ¡é—®é¢˜ï¼š

åˆ†æè¦æ±‚ï¼š
1. æ·±å…¥ç†è§£ä¸šåŠ¡èƒŒæ™¯å’Œæ•°æ®ç‰¹å¾
2. è¿ç”¨ç»Ÿè®¡å­¦å’Œä¸šåŠ¡é€»è¾‘è¿›è¡Œåˆ†æ
3. æä¾›å¯æ‰§è¡Œçš„å•†ä¸šå»ºè®®
4. è¯„ä¼°åˆ†æç»“æœçš„å¯ä¿¡åº¦
5. è¯†åˆ«æ½œåœ¨çš„é£é™©å’Œæœºä¼š

è¯·æä¾›ç»“æ„åŒ–çš„åˆ†æç»“æœã€‚"""),
                ("human", """æ•°æ®æè¿°ï¼š{data_description}

ä¸šåŠ¡é—®é¢˜ï¼š{business_question}

è¯·è¿›è¡Œæ·±å…¥åˆ†æå¹¶æä¾›æ´å¯Ÿï¼š""")
            ])
            
            try:
                analysis_chain = analysis_prompt | self.llm
                result = analysis_chain.invoke({
                    "data_description": data_description,
                    "business_question": question
                })
                
                # è§£æåˆ†æç»“æœï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”ç”¨ä¸­å¯èƒ½éœ€è¦æ›´å¤æ‚çš„è§£æé€»è¾‘ï¼‰
                insight = BusinessInsight(
                    insight_type="data_analysis",
                    title=f"å…³äº '{question}' çš„åˆ†ææ´å¯Ÿ",
                    description=result.content,
                    confidence=random.uniform(0.7, 0.95),  # ç¤ºä¾‹ç½®ä¿¡åº¦
                    recommendations=self._extract_recommendations(result.content),
                    impact_level=random.choice(["low", "medium", "high"])
                )
                insights.append(insight)
                
            except Exception as e:
                print(f"åˆ†æé—®é¢˜ '{question}' æ—¶å‡ºé”™ï¼š{e}")
                continue
        
        return insights
    
    def strategic_decision_support(self, decision_context: str, options: List[str], 
                                 constraints: List[str]) -> Dict[str, Any]:
        """æˆ˜ç•¥å†³ç­–æ”¯æŒæ¼”ç¤º"""
        
        decision_prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¼ä¸šæˆ˜ç•¥é¡¾é—®ã€‚è¯·ä¸ºå¤æ‚çš„å•†ä¸šå†³ç­–æä¾›ä¸“ä¸šåˆ†æï¼š

åˆ†ææ¡†æ¶ï¼š
1. ç°çŠ¶åˆ†æï¼ˆSWOTï¼‰
2. é€‰é¡¹è¯„ä¼°ï¼ˆä¼˜åŠ£åŠ¿å¯¹æ¯”ï¼‰
3. é£é™©è¯„ä¼°ï¼ˆé£é™©çŸ©é˜µï¼‰
4. å®æ–½å»ºè®®ï¼ˆè·¯çº¿å›¾ï¼‰
5. å…³é”®æˆåŠŸå› ç´ è¯†åˆ«

è¯·æä¾›ç³»ç»Ÿæ€§çš„å†³ç­–åˆ†ææŠ¥å‘Šã€‚"""),
            ("human", """å†³ç­–èƒŒæ™¯ï¼š{context}

å¯é€‰æ–¹æ¡ˆï¼š
{options}

çº¦æŸæ¡ä»¶ï¼š
{constraints}

è¯·æä¾›å†³ç­–åˆ†æï¼š""")
        ])
        
        try:
            decision_chain = decision_prompt | self.llm
            analysis_result = decision_chain.invoke({
                "context": decision_context,
                "options": "\n".join([f"é€‰é¡¹{i+1}ï¼š{opt}" for i, opt in enumerate(options)]),
                "constraints": "\n".join([f"çº¦æŸ{i+1}ï¼š{const}" for i, const in enumerate(constraints)])
            })
            
            # é£é™©è¯„ä¼°
            risk_prompt = ChatPromptTemplate.from_messages([
                ("system", "ä½ æ˜¯é£é™©ç®¡ç†ä¸“å®¶ã€‚è¯·è¯†åˆ«å†³ç­–ä¸­çš„æ½œåœ¨é£é™©å¹¶æä¾›ç¼“è§£ç­–ç•¥ã€‚"),
                ("human", "å†³ç­–åˆ†æï¼š{analysis}\nè¯·è¯†åˆ«é£é™©å’Œç¼“è§£æªæ–½ï¼š")
            ])
            
            risk_chain = risk_prompt | self.llm
            risk_result = risk_chain.invoke({"analysis": analysis_result.content})
            
            return {
                "decision_analysis": analysis_result.content,
                "risk_assessment": risk_result.content,
                "recommended_approach": self._extract_recommendation(analysis_result.content),
                "confidence_level": random.uniform(0.75, 0.9)
            }
            
        except Exception as e:
            return {"error": str(e), "analysis_success": False}
    
    def multi_turn_conversation(self, conversation_type: str = "sales") -> None:
        """å¤šè½®å¯¹è¯åœºæ™¯æ¼”ç¤º"""
        print(f"\nğŸ—£ï¸ å¼€å§‹{conversation_type}å¯¹è¯æ¼”ç¤ºï¼ˆè¾“å…¥ 'quit' é€€å‡ºï¼‰")
        print("-" * 50)
        
        # å®šä¹‰å¯¹è¯è§’è‰²
        role_prompts = {
            "sales": "ä½ æ˜¯ä¸“ä¸šçš„é”€å”®ä»£è¡¨ï¼Œç›®æ ‡æ˜¯äº†è§£å®¢æˆ·éœ€æ±‚å¹¶æ¨èåˆé€‚çš„äº§å“ã€‚",
            "support": "ä½ æ˜¯æŠ€æœ¯æ”¯æŒä¸“å®¶ï¼Œä¸“æ³¨äºè§£å†³å®¢æˆ·çš„æŠ€æœ¯é—®é¢˜ã€‚",
            "consultant": "ä½ æ˜¯ä¸šåŠ¡é¡¾é—®ï¼Œå¸®åŠ©å®¢æˆ·åˆ†æä¸šåŠ¡æŒ‘æˆ˜å¹¶æä¾›è§£å†³æ–¹æ¡ˆã€‚"
        }
        
        conversation_prompt = ChatPromptTemplate.from_messages([
            ("system", role_prompts.get(conversation_type, role_prompts["sales"])),
            MessagesPlaceholder(variable_name="chat_history"),
            ("human", "{input}")
        ])
        
        conversation_chain = conversation_prompt | self.llm
        
        while True:
            user_input = input("\nç”¨æˆ·: ")
            if user_input.lower() == 'quit':
                break
                
            try:
                # ç”Ÿæˆå›å¤
                response = conversation_chain.invoke({
                    "input": user_input,
                    "chat_history": self.message_history.messages
                })
                
                print(f"AIåŠ©æ‰‹: {response.content}")
                
                # ä¿å­˜åˆ°æ¶ˆæ¯å†å²
                self.message_history.add_user_message(user_input)
                self.message_history.add_ai_message(response.content)
                
                # ä¿æŒæ¶ˆæ¯å†å²åœ¨é™åˆ¶èŒƒå›´å†…
                if len(self.message_history.messages) > self.max_messages:
                    self.message_history.messages = self.message_history.messages[-self.max_messages:]
                
            except Exception as e:
                print(f"å¯¹è¯å‡ºé”™ï¼š{e}")
    
    def _extract_recommendations(self, analysis_text: str) -> List[str]:
        """ä»åˆ†ææ–‡æœ¬ä¸­æå–å»ºè®®ï¼ˆç®€åŒ–å®ç°ï¼‰"""
        # å®é™…åº”ç”¨ä¸­å¯èƒ½éœ€è¦æ›´å¤æ‚çš„NLPå¤„ç†
        recommendations = []
        lines = analysis_text.split('\n')
        for line in lines:
            if any(keyword in line.lower() for keyword in ['å»ºè®®', 'æ¨è', 'åº”è¯¥', 'å¯ä»¥è€ƒè™‘']):
                recommendations.append(line.strip())
        return recommendations[:5]  # æœ€å¤šè¿”å›5ä¸ªå»ºè®®
    
    def _extract_recommendation(self, analysis_text: str) -> str:
        """ä»åˆ†ææ–‡æœ¬ä¸­æå–ä¸»è¦å»ºè®®"""
        lines = analysis_text.split('\n')
        for line in lines:
            if 'æ¨è' in line or 'å»ºè®®' in line:
                return line.strip()
        return "éœ€è¦è¿›ä¸€æ­¥åˆ†æ"


def demonstrate_business_scenarios():
    """æ¼”ç¤ºå„ç§å•†ä¸šåœºæ™¯"""
    print("ğŸ¢ å•†ä¸šåœºæ™¯æŒ‘æˆ˜æ¼”ç¤º")
    print("=" * 60)
    
    demo = BusinessChallengesDemo()
    
    # 1. æ™ºèƒ½å®¢æœæ¼”ç¤º
    print("\n1ï¸âƒ£ æ™ºèƒ½å®¢æœåœºæ™¯æ¼”ç¤º")
    print("-" * 30)
    
    # åˆ›å»ºç¤ºä¾‹å®¢æˆ·æ¡£æ¡ˆ
    customer = CustomerProfile(
        customer_id="CUST001",
        name="å¼ å…ˆç”Ÿ",
        tier="VIP",
        purchase_history=[
            {"product": "ç¬”è®°æœ¬ç”µè„‘", "amount": 8999, "date": "2024-01-15"},
            {"product": "é¼ æ ‡", "amount": 299, "date": "2024-02-20"}
        ],
        preferences=["ç§‘æŠ€äº§å“", "é«˜æ€§èƒ½", "å“ç‰Œä¿éšœ"],
        contact_history=[
            {"type": "å’¨è¯¢", "content": "äº§å“ä¿ä¿®é—®é¢˜", "date": "2024-03-01"},
            {"type": "æŠ•è¯‰", "content": "é…é€å»¶è¿Ÿ", "date": "2024-03-10"}
        ]
    )
    
    query = "æˆ‘çš„ç¬”è®°æœ¬ç”µè„‘å¼€æœºå˜æ…¢äº†ï¼Œè¿™æ˜¯æ€ä¹ˆå›äº‹ï¼Ÿèƒ½å¸®æˆ‘çœ‹çœ‹å—ï¼Ÿ"
    
    try:
        service_response = demo.customer_service_bot(query, customer)
        print(f"å®¢æˆ·å’¨è¯¢ï¼š{query}")
        print(f"å®¢æœå›å¤ï¼š\n{service_response}")
    except Exception as e:
        print(f"å®¢æœæ¼”ç¤ºå‡ºé”™ï¼š{e}")
    
    # 2. å†…å®¹ç”Ÿæˆæµæ°´çº¿æ¼”ç¤º
    print("\n2ï¸âƒ£ å†…å®¹ç”Ÿæˆæµæ°´çº¿æ¼”ç¤º")
    print("-" * 30)
    
    try:
        content_result = demo.content_generation_pipeline(
            content_type="äº§å“ä»‹ç»æ–‡ç« ",
            target_audience="ç§‘æŠ€çˆ±å¥½è€…",
            key_points=["AIæŠ€æœ¯", "ç”¨æˆ·ä½“éªŒ", "æ€§ä»·æ¯”", "åˆ›æ–°åŠŸèƒ½"],
            brand_tone="ä¸“ä¸šä¸”æ˜“æ‡‚"
        )
        
        if content_result.get("generation_success"):
            print("ğŸ“‹ å†…å®¹ç­–ç•¥ï¼š")
            print(content_result["strategy"][:200] + "...")
            print("\nğŸ“ åŸå§‹å†…å®¹ï¼š")
            print(content_result["original_content"][:200] + "...")
            print("\nâœ¨ ä¼˜åŒ–å†…å®¹ï¼š")
            print(content_result["optimized_content"][:200] + "...")
        else:
            print(f"å†…å®¹ç”Ÿæˆå¤±è´¥ï¼š{content_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
    except Exception as e:
        print(f"å†…å®¹ç”Ÿæˆæ¼”ç¤ºå‡ºé”™ï¼š{e}")
    
    # 3. å•†ä¸šæ•°æ®åˆ†ææ¼”ç¤º
    print("\n3ï¸âƒ£ å•†ä¸šæ•°æ®åˆ†ææ¼”ç¤º")
    print("-" * 30)
    
    data_desc = """
    ç”µå•†å¹³å°2024å¹´Q1æ•°æ®ï¼š
    - æ€»è®¢å•æ•°ï¼š150ä¸‡
    - æ€»é”€å”®é¢ï¼š5.2äº¿å…ƒ
    - æ–°ç”¨æˆ·æ³¨å†Œï¼š32ä¸‡
    - ç”¨æˆ·å¤è´­ç‡ï¼š45%
    - ç§»åŠ¨ç«¯è®¢å•å æ¯”ï¼š78%
    - å¹³å‡è®¢å•ä»·å€¼ï¼š347å…ƒ
    """
    
    business_questions = [
        "å¦‚ä½•æå‡ç”¨æˆ·å¤è´­ç‡ï¼Ÿ",
        "ç§»åŠ¨ç«¯å æ¯”é«˜è¯´æ˜ä»€ä¹ˆï¼Ÿåº”è¯¥å¦‚ä½•ä¼˜åŒ–ï¼Ÿ",
        "æ–°ç”¨æˆ·è½¬åŒ–ç­–ç•¥æœ‰å“ªäº›æœºä¼šï¼Ÿ"
    ]
    
    try:
        insights = demo.business_data_analyst(data_desc, business_questions)
        for i, insight in enumerate(insights, 1):
            print(f"\næ´å¯Ÿ{i}ï¼š{insight.title}")
            print(f"æè¿°ï¼š{insight.description[:200]}...")
            print(f"ç½®ä¿¡åº¦ï¼š{insight.confidence:.2f}")
            print(f"å»ºè®®ï¼š{'; '.join(insight.recommendations[:2])}")
    except Exception as e:
        print(f"æ•°æ®åˆ†ææ¼”ç¤ºå‡ºé”™ï¼š{e}")
    
    # 4. æˆ˜ç•¥å†³ç­–æ”¯æŒæ¼”ç¤º
    print("\n4ï¸âƒ£ æˆ˜ç•¥å†³ç­–æ”¯æŒæ¼”ç¤º")
    print("-" * 30)
    
    decision_context = "å…¬å¸è®¡åˆ’è¿›å…¥æ–°çš„å¸‚åœºé¢†åŸŸï¼Œéœ€è¦åœ¨ä¸‰ä¸ªä¸åŒçš„æ–¹å‘ä¸­åšå‡ºé€‰æ‹©"
    options = [
        "æŠ•èµ„AIæ•™è‚²å¹³å°ï¼Œé¢„è®¡éœ€è¦2000ä¸‡å¯åŠ¨èµ„é‡‘",
        "å¼€å‘ä¼ä¸šçº§SaaSå·¥å…·ï¼Œé¢„è®¡éœ€è¦1500ä¸‡å¯åŠ¨èµ„é‡‘", 
        "è¿›å†›æµ·å¤–ç”µå•†å¸‚åœºï¼Œé¢„è®¡éœ€è¦3000ä¸‡å¯åŠ¨èµ„é‡‘"
    ]
    constraints = [
        "å¯ç”¨èµ„é‡‘æ€»é¢ä¸º2500ä¸‡",
        "å¿…é¡»åœ¨18ä¸ªæœˆå†…çœ‹åˆ°åˆæ­¥æˆæœ",
        "å›¢é˜Ÿè§„æ¨¡ä¸èƒ½è¶…è¿‡50äºº"
    ]
    
    try:
        decision_result = demo.strategic_decision_support(decision_context, options, constraints)
        if decision_result.get("analysis_success", True):
            print(f"å†³ç­–åˆ†æï¼š\n{decision_result['decision_analysis'][:300]}...")
            print(f"\né£é™©è¯„ä¼°ï¼š\n{decision_result['risk_assessment'][:200]}...")
            print(f"\næ¨èæ–¹æ¡ˆï¼š{decision_result['recommended_approach']}")
            print(f"ç½®ä¿¡æ°´å¹³ï¼š{decision_result.get('confidence_level', 0.8):.2f}")
        else:
            print(f"å†³ç­–åˆ†æå¤±è´¥ï¼š{decision_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
    except Exception as e:
        print(f"å†³ç­–æ”¯æŒæ¼”ç¤ºå‡ºé”™ï¼š{e}")
    
    # 5. å¤šè½®å¯¹è¯æ¼”ç¤ºï¼ˆäº¤äº’å¼ï¼‰
    print("\n5ï¸âƒ£ å¤šè½®å¯¹è¯æ¼”ç¤º")
    print("-" * 30)
    print("å¯é€‰å¯¹è¯ç±»å‹ï¼šsalesï¼ˆé”€å”®ï¼‰ã€supportï¼ˆæŠ€æœ¯æ”¯æŒï¼‰ã€consultantï¼ˆé¡¾é—®å’¨è¯¢ï¼‰")

async def run_business_challenges_demo():
    """è¿è¡Œä¸šåŠ¡æŒ‘æˆ˜æ¼”ç¤º - åŒ…è£…å‡½æ•°ç”¨äºç»Ÿä¸€æ¥å£"""
    demonstrate_business_scenarios()
    
    # æ³¨æ„ï¼šè¿™ä¸ªæ¼”ç¤ºéœ€è¦ç”¨æˆ·äº¤äº’ï¼Œåœ¨è‡ªåŠ¨åŒ–æ¼”ç¤ºä¸­å¯èƒ½ä¸é€‚åˆ
    # demo.multi_turn_conversation("sales")


if __name__ == "__main__":
    demonstrate_business_scenarios()